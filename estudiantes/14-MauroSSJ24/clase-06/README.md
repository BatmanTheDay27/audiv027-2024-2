# clase

Hoy hay que investigar_los proyectos anteriores.

Actividad:
_naveguen por los repos de este curso en sus otras versiones
en particular en los proyectos 1 y 2 de los estudiantes_

https://github.com/FAU-UChile/audiv027-2024-1
https://github.com/FAU-UChile/audiv027-2023-2

_incluir en sus apuntes datos sobre integrantes, githubs,
codigo, materiales, que version de que software usaron, que tecnologia usaron_

_Incluir qué tipo de proyecto quieren hacer_
_Qué herramientas ya saben_
_Qué herramientas quieren que veamos hoy en la segunda mitad_

_Revisando...
AUDIV027-2023-2
Entre la clase 06 y 07 estan los apuntes del primer trabajo grupal del curso.
1.- Me llamo la atencion el "pinta con handpose"
https://github.com/msvioletasr/audiv027-2023-2/tree/main/clases/clase-07/estudiantes/01100100i
Handpose y Drawing Patterns.
Material usado: p5 editor, ml5js, ml4a.net/ml5, chatgpt.
Material requerido: Una mano, camara.
*ml4a es una colección de herramientas y recursos educativos que aplican técnicas de aprendizaje automático a las artes y la creatividad. brinda opciones en donde las imagenes se utilizan para lograr acciones mediante una camara.


2.- Reconocimiento de voz
Integrantes: Violeta Silva, Fae Ávila y Kamila Mansilla
https://github.com/msvioletasr/audiv027-2023-2/tree/main/clases/clase-07/estudiantes/msvioletasr
Para crear este modelo usamos el tutorial sobre SoundClassification de learn.ml5js.org. Duplicamos y editamos el ejemplo incluido en esa página. Además, usamos el modo de audio de Teachable Machine para entrenar nuestro modelo.
-Computador o celular -Micrófono -Conexión a internet -Voz
En este proyecto se tomo en cuenta en primer lugar Shazam, ya que queríamos simular la identificación de música que logra hacer esta aplicación, y para esto queríamos usar Sound Classification, pero teniendo en cuenta la complejidad para programar algo así, decidimos tomar como referente diversos reconocimientos de voz, grabando nuestras propias voces.
Biometría de voz: Sistema de identificación Google usa inteligencia artificial para crear un modelo de voz



3.-Are you smiling yet?
https://github.com/FAU-UChile/audiv027-2023-2/tree/main/clases/clase-07/estudiantes/Anemix011
Basándonos en el modelo de Facemesh en siguiente arículo de koraboo para determinar parámetros que pudiésemos utilizar para que el programa decidiese otorgar cada arquetipo a la persona frente a la cámara.
*Emplea aprendizaje automático (ML) para inferir la superficie facial 3D , requiriendo solo una única entrada de cámara sin la necesidad de un sensor de profundidad dedicado
*Qué es un Koreaboo? - Quora. Prácticamente es una persona obsesionada con la cultura Coreana, al nivel que renuncian a sus propias costumbres y tradiciones para seguir a Corea.
Ingresamos a ml5, y accedimos a las referencias, y el modelo de Facemsh en el editor p5.js. Este modelo genera una malla de 486 puntos en base a determinados keypoints en el rostro de una persona enfrentada a la cámara web.
Verificamos que funcionaba bien el modelo base, y luego nos propusimos determinar los parámetros. Sin embargo, nos resultó muy díficil encontrar como referencia sólo determinados keypoints. Logramos encontrar la malla base del modelo en el repositorio de Github.







*Hacer click en los cambios detras_behind_ para solo quedar así, aparte de los 9cummints behind.
agregar en crear pull request_necesariamente ponerle un titulo y eso crea un pull request que es una propuesta de cambios que propongo como estudiante al administrador. 
(una vez aceotado por el admin) se cierra el pull request. así 







